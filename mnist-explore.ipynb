{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-30T16:44:31.861904Z","iopub.execute_input":"2024-04-30T16:44:31.862498Z","iopub.status.idle":"2024-04-30T16:44:31.872885Z","shell.execute_reply.started":"2024-04-30T16:44:31.862456Z","shell.execute_reply":"2024-04-30T16:44:31.871616Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install lightning","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:44:31.875119Z","iopub.execute_input":"2024-04-30T16:44:31.875554Z","iopub.status.idle":"2024-04-30T16:44:48.996712Z","shell.execute_reply.started":"2024-04-30T16:44:31.875518Z","shell.execute_reply":"2024-04-30T16:44:48.995065Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: lightning in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\nRequirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.0)\nRequirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.2)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: torch<4.0,>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2+cpu)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.3.2)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.1)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nImports\n\"\"\"\n\nimport os\nfrom dataclasses import dataclass\n\nimport lightning as L\nimport lightning.pytorch as pl\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as T\nimport torchvision.transforms.functional as TF\nfrom lightning.pytorch.callbacks import EarlyStopping, StochasticWeightAveraging, LearningRateMonitor, ModelCheckpoint, TQDMProgressBar\nfrom lightning.pytorch.loggers import TensorBoardLogger\nfrom sklearn.model_selection import train_test_split\n\ntorch.set_float32_matmul_precision('medium')","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:44:48.998681Z","iopub.execute_input":"2024-04-30T16:44:48.999123Z","iopub.status.idle":"2024-04-30T16:44:49.009892Z","shell.execute_reply.started":"2024-04-30T16:44:48.999080Z","shell.execute_reply":"2024-04-30T16:44:49.008391Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass TrainingConfig:\n    image_size = 28  # the generated image resolution\n\n    train_batch_size = 128\n    val_batch_size = 128\n\n    max_epochs = 15\n    check_val_every_n_epoch = 1\n    accumulate_grad_batches = 1\n    learning_rate = 1e-6\n\n    output_dir = \"lightning\"\n\n    seed = 10\n\n\nconfig = TrainingConfig()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:44:49.013379Z","iopub.execute_input":"2024-04-30T16:44:49.013941Z","iopub.status.idle":"2024-04-30T16:44:49.025584Z","shell.execute_reply.started":"2024-04-30T16:44:49.013897Z","shell.execute_reply":"2024-04-30T16:44:49.024040Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"transform = T.Compose([\n    T.ToPILImage(),\n    T.Resize((config.image_size, config.image_size)),\n    T.ToTensor(),\n    T.Normalize([0.5], [0.5]),\n    T.ToPILImage(),\n])\n\nreverse_transform = T.Compose([\n    # T.Resize((config.image_size, config.image_size)),\n    T.ToTensor(),\n    T.Normalize([-0.5/0.5], [1/0.5]),\n    T.ToPILImage(),\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:44:49.027859Z","iopub.execute_input":"2024-04-30T16:44:49.028351Z","iopub.status.idle":"2024-04-30T16:44:49.039288Z","shell.execute_reply.started":"2024-04-30T16:44:49.028313Z","shell.execute_reply":"2024-04-30T16:44:49.038027Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"class MNISTDataset(torch.utils.data.Dataset):\n    def __init__(self, labels: pd.DataFrame, images: pd.DataFrame, transform=None):\n        super().__init__()\n        self.labels = labels\n        self.images = images\n        assert len(self.labels) == len(self.images)\n        \n        self.transform = transform\n\n    def __len__(self):\n        length = len(self.labels)\n        return length\n\n    def __getitem__(self, index):\n        label = self.labels[index]\n        image = self.images[index]\n        # print(f'Reading : {image}')\n        # image = torchvision.io.read_image(image)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return label, image","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:44:49.041452Z","iopub.execute_input":"2024-04-30T16:44:49.041892Z","iopub.status.idle":"2024-04-30T16:44:49.057745Z","shell.execute_reply.started":"2024-04-30T16:44:49.041854Z","shell.execute_reply":"2024-04-30T16:44:49.056363Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"class MNISTDataModule(L.LightningDataModule):\n    def __init__(self,\n                 train_transform,\n                 test_transform):\n        super().__init__()\n        self.num_workers = os.cpu_count()  # <- use all available CPU cores\n\n        self.train_transform = train_transform\n        self.test_transform = test_transform\n\n        self.train_dataset = None\n        self.val_dataset = None\n        self.test_dataset = None\n\n    def setup(self, stage: str):\n        if stage == \"fit\":\n            train_data = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n            # samples = samples.sample(frac=0.4)\n            train_data, val_data = train_test_split(\n                train_data, \n                train_size=0.7, \n                shuffle=False)\n            \n            train_labels = train_data.label\n            val_labels = val_data.label\n            \n            # Reshaping data\n            train_images = train_data.iloc[:,1:].values.reshape(len(train_data), 28, 28)\n            val_images = val_data.iloc[:,1:].values.reshape(len(val_data), 28, 28)\n            \n            train_images = torch.from_numpy(train_images).type(torch.DoubleTensor)\n            val_images = torch.from_numpy(val_images).type(torch.DoubleTensor)\n            \n#             train_images = train_images.astype(np.float64)\n#             val_images = val_images.astype(np.float64)\n                              \n            self.train_dataset = MNISTDataset(\n                labels=train_labels,\n                images=train_images,\n                transform=self.train_transform\n            )\n\n            self.val_dataset = MNISTDataset(\n                labels=val_labels,\n                images=val_images,\n                transform=self.test_transform\n            )\n\n            print(f\"Total Dataset       : {len(self.train_dataset) + len(self.val_dataset)} samples\")\n            print(f\"Train Dataset       : {len(self.train_dataset)} samples\")\n            print(f\"Validation Dataset  : {len(self.val_dataset)} samples\")\n        \n        if stage == 'predict':\n            samples = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\n            labels = samples.label\n            images = samples.iloc[:,1:].values.reshape(len(samples), 28, 28)\n            images = torch.from_numpy(images)\n            \n            self.test_dataset = MNISTDataset(\n                labels=labels,\n                images=images,\n                transform=self.test_transform\n            )\n            \n            print(f\"Test Dataset  : {len(self.test_dataset)} samples\")\n            \n    def train_dataloader(self):\n        return torch.utils.data.DataLoader(\n            self.train_dataset,\n            batch_size=config.train_batch_size,\n            shuffle=True,\n            num_workers=self.num_workers,\n            persistent_workers=True,\n            pin_memory=True,\n        )\n\n    def val_dataloader(self):\n        return torch.utils.data.DataLoader(\n            self.val_dataset,\n            batch_size=config.val_batch_size,\n            shuffle=False,\n            num_workers=self.num_workers,\n            persistent_workers=True,\n            pin_memory=True,\n        )","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:44:49.059277Z","iopub.execute_input":"2024-04-30T16:44:49.060359Z","iopub.status.idle":"2024-04-30T16:44:49.080369Z","shell.execute_reply.started":"2024-04-30T16:44:49.060319Z","shell.execute_reply":"2024-04-30T16:44:49.079014Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"dm = MNISTDataModule(\n    train_transform=transform,\n    test_transform=transform\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:44:49.082006Z","iopub.execute_input":"2024-04-30T16:44:49.082424Z","iopub.status.idle":"2024-04-30T16:44:49.105216Z","shell.execute_reply.started":"2024-04-30T16:44:49.082388Z","shell.execute_reply":"2024-04-30T16:44:49.103715Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"dm.setup(stage='fit')","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:44:49.107557Z","iopub.execute_input":"2024-04-30T16:44:49.108528Z","iopub.status.idle":"2024-04-30T16:44:53.104565Z","shell.execute_reply.started":"2024-04-30T16:44:49.108482Z","shell.execute_reply":"2024-04-30T16:44:53.103118Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Total Dataset       : 42000 samples\nTrain Dataset       : 29399 samples\nValidation Dataset  : 12601 samples\n","output_type":"stream"}]},{"cell_type":"code","source":"label, img = dm.train_dataset[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:49:41.524364Z","iopub.execute_input":"2024-04-30T16:49:41.525198Z","iopub.status.idle":"2024-04-30T16:49:41.533786Z","shell.execute_reply.started":"2024-04-30T16:49:41.525149Z","shell.execute_reply":"2024-04-30T16:49:41.532184Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"img","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:49:41.977493Z","iopub.execute_input":"2024-04-30T16:49:41.978836Z","iopub.status.idle":"2024-04-30T16:49:41.989759Z","shell.execute_reply.started":"2024-04-30T16:49:41.978757Z","shell.execute_reply":"2024-04-30T16:49:41.988395Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"<PIL.Image.Image image mode=L size=128x128>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"label","metadata":{"execution":{"iopub.status.busy":"2024-04-30T16:49:42.809092Z","iopub.execute_input":"2024-04-30T16:49:42.809597Z","iopub.status.idle":"2024-04-30T16:49:42.817823Z","shell.execute_reply.started":"2024-04-30T16:49:42.809560Z","shell.execute_reply":"2024-04-30T16:49:42.816452Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}